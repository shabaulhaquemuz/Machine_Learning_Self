{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8a5e95-fd31-4826-b9ce-b77824e777ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is naive-bayes ?\n",
    "#Naive Bayes is a supervised probablistic machine learning model based on bayes theorem. It is mostly used for classification problem such\n",
    "#email spam detection, medical diagnosis and it is called Naive because it assumes all features are independent of each other and it is called bayes\n",
    "#because it is based on bayes theorem of probability.\n",
    "#Bayes theorem is used to update the probability of a hypothesis class based on new evidence\n",
    "\n",
    "# P(C∣X)=P(X∣C)⋅P(C))/P(X)\n",
    "# where\n",
    "# P(C∣X)= probability of class c given feature x\n",
    "# P(X∣C)= probability of x feature in given class c\n",
    "# P(C)= prior probability of class\n",
    "# P(X)=evidence(probability of features of all classes)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53109842-769b-4334-b487-43a81aca5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advantages of Naive Bayes:\n",
    "#1. Fast and efficient\n",
    "#2. It works well with high dimensional data\n",
    "#3. It requires small training data\n",
    "#4. It handles noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d222a7-997e-484f-a9b1-525cdfd97ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limitations:\n",
    "# 1. It assumes independence of features\n",
    "# 2. It is not suitable for features with strong correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61f0ab4-da57-4eed-b51d-d79df8f6774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task(Mathematically):\n",
    "#Suppose we want tp classify whether a person buy a computer(Yes/No) based on 2 features:\n",
    "#1.Age(Young,Middle,Old) 2.Income(High, Medium, Low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ebb3a-57ee-4e73-9f4e-8333689c2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset(of below 4 columns):\n",
    "# 1. Person:1,2,3,4,5,6\n",
    "# 2. Age = young,young, middle,old,old,medium\n",
    "# 3. Income= High,Medium,high,medium,low,low\n",
    "# 4. Buys Computer= No,No,Yes,Yes,Yes,No\n",
    "\n",
    "#Step1: we calculate how many people bought verses how many people did not buy a computer\n",
    "#Total=6,Yes=3,No=3\n",
    "#Probability of Yes=3/6=0.5\n",
    "#Probability of No=3/6=0.5\n",
    "\n",
    "#Step2: Now we compute probabilities of features given the Class\n",
    "#For class=Yes,P(Age middle(yes)=1/3,P(Age OLd(yes)=2/3, P(Income High(yes)=1/3, P(Income Medium(yes)=1/3, P(Income Low(yes)=1/3\n",
    "#For class=No,P(Age young(No)=2/3,P(Age OLd(No)=0/3, P(Income High(no)=1/3, P(Income Medium(no)=1/3, P(Income Low(no)=1/3\n",
    "\n",
    "#Step3: Now suppose we want to predict for a new person, whose age is old and income is medium:\n",
    "# P(Yes)/P(old)*P(medium) = p(old)* p(medium)/P(yes)\n",
    "# P(No)/P(old)*P(medium) = p(old)* p(medium)/P(No)\n",
    "\n",
    "#Step4: Decision\n",
    "#P(Yes)/p(old)*p(medium)=0.1111\n",
    "#P(No)/p(old)*p(medium)=0\n",
    "# probability of yes is more, so model will predict yes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2227f0d5-a23f-42bf-a625-89989fad90bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Person     Age  Income Buys_Computer\n",
      "0       1   young     low            no\n",
      "1       2   young     low            no\n",
      "2       3  middle    high           yes\n",
      "3       4     old  medium           yes\n",
      "4       5     old     low           yes\n",
      "5       6  medium     low            no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create dataset as dictionary\n",
    "data = {\n",
    "    \"Person\": [1, 2, 3, 4, 5, 6],\n",
    "    \"Age\": [\"young\", \"young\", \"middle\", \"old\", \"old\", \"medium\"],\n",
    "    \"Income\": [\"low\", \"low\", \"high\", \"medium\", \"low\", \"low\"],\n",
    "    \"Buys_Computer\": [\"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\"]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9735ab-90f8-49c3-8168-4eec1be88a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Types of Naive Bayes:\n",
    "#1. Multinomial Naive Bayes: For test classification and word counts.\n",
    "#2.Bernoulli Naive Bayes: For binary features(word-Present or Not)\n",
    "#3. Gaussian Naive Bayes: For continuous Features or normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229f939-7280-480d-bc6a-baeb8f7b1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: What are the advantages and limitaion of naive bayes\n",
    "#what is laplace and smoothing in naive bayes\n",
    "#how is naive bayes different from logistic regression\n",
    "#In what scenarios does naive bayes perform poorly\n",
    "#how does naive baiyes perform in high dimensional data like text?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
